---
title: Install On-Prem
icon: "download"
iconType: "solid"
---
 

Upsonic On-Prem consists of two subsystems: the Dashboard and the API. Both systems run in a single container and connect internally. This document guides you through the installation and execution of the container without any issues.

To get started, you will need:

- The latest version of Docker installed and functioning properly
- TCP ports 7501 and 7500 ready for use

## Deployment

First, we will create a volume to store everything:

```console
docker volume create upsonic_on_prem_data
```


Setting .env

```console
nano .env
```

```console
admin_key=YOUR_ADMIN_KEY_FOR_API # 123
admin_pass=YOUR_ADMIN_PASS_FOR_DASHBOARD # 123456
admin_username=YOUR_ADMIN_USERNAME #upsonic_admin
```

after adjusting the settings, you can exit by pressing Ctrl+X, then confirming with 'Y' and pressing Enter.


Now, let's proceed with the download, installation, and execution of the Upsonic On-Prem container:

```console
docker run --env-file .env -d -p 7501:7501 -p 7500:7500 --name upsonic_on_prem --restart=always -v upsonic_on_prem_data:/var/lib/redis ghcr.io/upsonic/on-prem:latest
```

After that, you should see:
```console
root@server:~# docker ps
CONTAINER ID   IMAGE                     COMMAND          CREATED          STATUS          PORTS                                                           NAMES
918a4c74185a   ghcr.io/upsonic/on-prem   "bash /run.sh"   11 seconds ago   Up 10 seconds   0.0.0.0:7500-7501->7500-7501/tcp, :::7500-7501->7500-7501/tcp   upsonic_on_prem
```

## Extra Options
### Limiting Model CPU usage
Limiting model CPU usage is improves the general performance of application. Because if you dont specify anything the model can take whole CPU to making analyses. But with this env variable you can limit how many CPU core that you want to give to model:

```console
main_model_cpu=3
```

### Using OpenAI Model Instead of Gemma
If you want to use OpenAI `gpt-3.5-turbo` or `gpt-4` models to use as default model. You just need to specify env variables.

```console
openai_api_key=YOUR_OPENAI_API_KEY
default_model=gpt-4 # or gpt-3.5-turbo
```



## Logging In
Now, you can access your Upsonic On-Prem via localhost or any other method of accessing your server:
```console
https://localhost:7501
````

